"""
Agentic Pipeline Runner for Superstore Transformation
Uses the full Data-PipeLiner agentic flow:
  Orchestrator â†’ SchemaAnalyst â†’ TransformationPlanner â†’ ExecutionEngine â†’ ValidationAgent
"""
import sys
from pathlib import Path

# Add project root to path
sys.path.insert(0, str(Path(__file__).parent))

from src.agents import Orchestrator
from src.schemas.additional_schemas import SUPERSTORE_ORDER_SCHEMA, SCHEMA_REGISTRY


def main():
    print("=" * 70)
    print("ğŸ¤– DATA-PIPELINER AGENTIC TRANSFORMATION")
    print("=" * 70)
    print()
    
    # Source file
    source_file = "Sample - Superstore.xls"
    target_schema = "superstore_order"
    
    print(f"ğŸ“‚ Source: {source_file}")
    print(f"ğŸ¯ Target Schema: {target_schema}")
    print(f"ğŸ“‹ Schema Description: {SUPERSTORE_ORDER_SCHEMA.description}")
    print()
    
    # Display target schema columns
    print("ğŸ¯ Target Schema Columns:")
    for col in SUPERSTORE_ORDER_SCHEMA.columns:
        req = "âœ“" if col.required else " "
        hint = f" â† {col.transformation_hint}" if col.transformation_hint else ""
        print(f"   [{req}] {col.name} ({col.data_type}){hint}")
    print()
    
    # Initialize the Orchestrator
    print("=" * 70)
    print("ğŸš€ STARTING AGENTIC PIPELINE")
    print("=" * 70)
    print()
    
    orchestrator = Orchestrator()
    
    # Create job
    print("ğŸ“ Creating transformation job...")
    job = orchestrator.create_job(source_file, target_schema)
    print(f"   âœ“ Job ID: {job.job_id}")
    print(f"   âœ“ Status: {job.status}")
    print()
    
    # Run the pipeline
    print("âš™ï¸  Running agentic pipeline...")
    print("-" * 70)
    
    job = orchestrator.run_job(job)
    
    print("-" * 70)
    print()
    
    # Report results
    print("=" * 70)
    print("ğŸ“Š PIPELINE RESULTS")
    print("=" * 70)
    print()
    
    print(f"ğŸ·ï¸  Final Status: {job.status}")
    
    if job.source_analysis:
        print(f"\nğŸ“ˆ Source Analysis:")
        print(f"   â€¢ Columns: {len(job.source_analysis.columns)}")
        print(f"   â€¢ Rows: {job.source_analysis.total_rows}")
        print(f"   â€¢ Quality: {job.source_analysis.overall_quality}")
    
    if job.transformation_plan:
        print(f"\nğŸ—ºï¸  Transformation Plan:")
        print(f"   â€¢ Column Mappings: {len(job.transformation_plan.column_mappings)}")
        print(f"   â€¢ Confidence: {job.transformation_plan.confidence_score:.0%}")
        
        if job.transformation_plan.column_mappings:
            print(f"\n   Mappings:")
            for mapping in job.transformation_plan.column_mappings[:10]:
                print(f"      {mapping.source_col} â†’ {mapping.target_col}")
    
    if job.validation_report:
        print(f"\nâœ… Validation Report:")
        print(f"   â€¢ Quality Score: {job.validation_report.quality_score:.0f}%")
        print(f"   â€¢ Successful Rows: {job.validation_report.successful_rows}")
        print(f"   â€¢ Failed Rows: {job.validation_report.failed_rows}")
        print(f"   â€¢ Errors: {len(job.validation_report.errors)}")
        print(f"   â€¢ Status: {job.validation_report.status}")
    
    if job.output_file:
        print(f"\nğŸ’¾ Output File: {job.output_file}")
    
    if job.error_message:
        print(f"\nâŒ Error: {job.error_message}")
    
    if job.pending_questions:
        print(f"\nâ“ Pending Questions:")
        for q in job.pending_questions:
            print(f"   â€¢ {q}")
    
    print()
    print("=" * 70)
    print("ğŸ PIPELINE COMPLETE")
    print("=" * 70)
    
    return job


if __name__ == "__main__":
    main()
